{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=10>Data organization</font><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we use the data from EEG Motor Movement/Imagery Dataset (EEG-MMIDB)[<sup>1</sup>](#refer-anchor-1). We offer the cleaned dataset that extract from the EEG-MMIDB that contains 109 subjects. In this Notebook, for simplicity, we take a subject as a subset to show how the code works.\n",
    "\n",
    "\n",
    "<!-- > Dataset_1: the data of the first subject in the EEG-MMIDB.  \n",
    "> Dataset_2: data of all 109 subjects of the EEG-MMIDB.\n",
    "\n",
    "* Note: in the following models of this BCI Notebook, we will use Dataset_1 to run examples for the computational advantage. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "The original dataset description can be find here: https://archive.physionet.org/pn4/eegmmidb/\n",
    "\n",
    "After our clearning and sorting, each .npy file comprised of the data of one subject. The data shape of each npy file is [N, 65], the first 64 columns represent the readouts of 64 EEG channel, the last column denotes the class/intent label. The row denotes time-points in signal collection and one row represents one readout at a specific time-point. In this Notebook, we call each row a instance. The sampling rate in EEG-MMIDB is 160 Hz, which means that the equipment can generate 160 instances/rows/time-points in each second.\n",
    "\n",
    "\n",
    "The N varis for different subjects, but N should be 259,520 or 255,680. This is the inherent difference in the original dataset. Recall that the sampling rate is 160 Hz, thus, some trials last for 4.1 seconds while others last for 4.2 seconds: 4.1 seconds (656=4.1 $\\times$ 160 instances) or 4.2 seconds (672 = 4.2 $\\times$  160 instancs). It is suggested to segment the signals in each second. \n",
    "\n",
    "\n",
    "Based on the experimental setting, we split all EEG signals into 11 different cognitive intentions as follows. In which, the intentions with *image* represents the subject only image the action but not move in reality: these four intentions (labelled by 4, 5, 8, and 9) are strictly *movement imagery EEG*. The residual intentions are rather the mental states that the user was conducting a specific action.\n",
    "> Labels:  \n",
    "0: open eyes,  \n",
    "1: close eyes.  \n",
    "2: left hand,   \n",
    "3: right hand.  \n",
    "4: image left hand,   \n",
    "5: image right hand.  \n",
    "6: open fists,   \n",
    "7:open feet.  \n",
    "8: image fist,   \n",
    "9: image feet.  \n",
    "10: rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, we show how to load the data in 2 commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Dataset_1: (259520, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-16, -29,   2, ..., -11,  15,   0],\n",
       "       [-56, -54, -27, ...,   1,  21,   0],\n",
       "       [-55, -55, -29, ...,  18,  35,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset_1=np.load('1.npy')\n",
    "print('The shape of Dataset_1:', dataset_1.shape)\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the data of subject 1 consists of 259520 instances and 64 channels while the last column denotes the class label (ground truth).\n",
    "\n",
    "We first introduce several terms about the data orgnization:\n",
    "* Instance (time step or time point). Each instance indicates a list of values which are collected at a single time point or sampling point. For example, there will be 160 instances in 1 second for the equipment with 160 Hz sampling rate. We use instance and time point interchangeably.\n",
    "\n",
    "* Segment (sample). Each segment contains multiple continue instances which can represent a specific event/state of brain signals. The length of a segment is called time window. We use segment and sample interchangeably.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "Next, we introduce the implementation of resampling in different conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this Notebook,we do not need resampling since our data has appropriate sampling frequency and is already balanced.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "Sometimes we need to filter the EEG signals into frequency bands of interests, in order to find the most informative and distinguishable patterns. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EEG signals collected from any typical EEG hardware have several nonoverlapping frequency bands (Delta, Theta, Alpha, Beta, and Gamma) based on the strong intraband correlation with a distinct behavioral state. Each EEG pattern contains signals associated with particular brain information. The degree of awareness denotes the perception of individuals when presented with external stimuli. It is mainly defined in physiology instead of psychology.[<sup>3</sup>](#refer-anchor-3)  \n",
    "\n",
    "Each frequency band represents a brain state and a qualitative assessment of awareness:\n",
    "* Delta pattern (0.5--4 Hz) corresponds to deep sleep when the subject has lower awareness.  \n",
    "- Theta pattern (4--8 Hz) corresponds to light sleep in the realm of low awareness.   \n",
    "* Alpha pattern (8--12 Hz) mainly occurs during eyes closed and deeply relaxed state and corresponds to the medium awareness. \n",
    "* Beta pattern (12--30 Hz) is the dominant rhythm while the eyes of the subject are open and is associated with high awareness. Beta patterns capture most of our daily activities (such as eating, walking, and talking). \n",
    "* Gamma pattern (30--100 Hz) represents the co-interaction of several brain areas to carry out a specific motor and cognitive function. \n",
    "\n",
    "Next, we provide the filtering codes taking the Delta band as an example (we don't need filtering in this Notebook, just provide the code in case the readers need it). The filter used here is 3-order band-pass butterworth filter. Please adjust sampling frequency (fs), lowcut and highcut to customize your own filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from BCI_functions.ipynb\n",
      "The shape of filtered feature: (259520, 64)\n",
      "The shape of dataset_1 after filtering: (259520, 65)\n"
     ]
    }
   ],
   "source": [
    "import myimporter  # active import from inside notebook\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this Notebook \n",
    "\n",
    "n_fea = 64  # 64 channels\n",
    "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
    "feature = dataset_1[:, 0:n_fea] \n",
    "feature_f=[]  # feature after filtering\n",
    "\n",
    "# EEG Delta pattern decomposition\n",
    "for i in range(feature.shape[1]):\n",
    "    x = feature[:, i]\n",
    "    fs = 160.0\n",
    "    lowcut = 0.5\n",
    "    highcut = 4.0\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
    "    feature_f.append(y) \n",
    "    \n",
    "feature_f=np.array(feature_f).T\n",
    "print('The shape of filtered feature:',feature_f.shape)\n",
    "\n",
    "data_f=np.hstack((feature_f,label))  # stack label to filtered feature \n",
    "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220](http://circ.ahajournals.org/cgi/content/full/101/23/e215)\n",
    "\n",
    "\n",
    "<div id=\"refer-anchor-2\"></div>\n",
    "\n",
    "- [3]  [Zhang X, Yao L, Wang X, et al. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers[J]. Journal of Neural Engineering, 2020.](https://arxiv.org/abs/1905.04149)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
